{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8023278,"sourceType":"datasetVersion","datasetId":4728069},{"sourceId":8023349,"sourceType":"datasetVersion","datasetId":4728119},{"sourceId":8023379,"sourceType":"datasetVersion","datasetId":4728140},{"sourceId":8042498,"sourceType":"datasetVersion","datasetId":4741742}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nimport torch\nfrom tensorflow import keras\nfrom transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## the process of creating class-prompts","metadata":{}},{"cell_type":"markdown","source":"---\n##### # Load the CSV data\n##### csv_file_path = '/kaggle/input/brain-dead-multimodal-data-for-hateful-meme/hateful_memes/hateful_memes_original.csv' \n##### data = pd.read_csv(csv_file_path)\n\n##### data['prompt'] = data['img']\n##### print(data.head())","metadata":{}},{"cell_type":"markdown","source":"---\n##### from tensorflow.keras.applications.resnet import ResNet50, preprocess_input, decode_predictions\n##### from tensorflow.keras.preprocessing import image\n\n##### # Load the ResNet-50 model pre-trained on ImageNet weights\n##### model = ResNet50(weights='imagenet')\n##### model = model.to(device)\n","metadata":{}},{"cell_type":"markdown","source":"---\n##### def preprocess_image(img_path):\n#####    img = image.load_img(img_path, target_size=(224, 224))\n#####     img = image.img_to_array(img)\n#####     img = np.expand_dims(img, axis=0)\n#####     img = preprocess_input(img)\n    \n#####     # Make a copy of the array to ensure no negative strides\n#####     img_copy = img.copy()\n    \n#####    # Convert the copy to a PyTorch tensor\n#####     img_tensor = torch.tensor(img_copy)\n#####     img_tensor = img_tensor.to(device)\n    \n#####     return img_tensor\n\n##### def classify_and_caption(img_path):\n#####     img = preprocess_image(img_path)\n    \n#####     preds = model.predict(img , verbose=0)\n    \n#####     decoded_preds = decode_predictions(preds, top=10)[0]  \n#####     high_conf_preds = [f\"{label} \" for (_, label, prob) in decoded_preds if prob > 0.3]\n    \n#####     caption = \", \".join(high_conf_preds) if high_conf_preds else \"messy\"\n    \n#####     return caption","metadata":{}},{"cell_type":"markdown","source":"---\n##### image_captions = []\n##### i = 0\n##### for img_path in data['img']:\n#####    img_path2 = os.path.join('/kaggle/input/brain-dead-multimodal-data-for-hateful-meme/hateful_memes', img_path)\n#####     caption = classify_and_caption(img_path2)\n#####     i+=1\n#####     print(i,end=\",\")\n#####     if i % 100 == 0 : \n#####         print() \n#####     image_captions.append(caption)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T13:35:13.639821Z","iopub.execute_input":"2024-04-06T13:35:13.640451Z","iopub.status.idle":"2024-04-06T13:35:13.644760Z","shell.execute_reply.started":"2024-04-06T13:35:13.640423Z","shell.execute_reply":"2024-04-06T13:35:13.643812Z"}}},{"cell_type":"markdown","source":"---\n##### image_captions = pd.DataFrame(image_captions)\n##### data['prompt'] = image_captions ","metadata":{}},{"cell_type":"markdown","source":"---\n##### data.to_csv( '/kaggle/working/one152.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T13:35:39.502240Z","iopub.execute_input":"2024-04-06T13:35:39.503115Z","iopub.status.idle":"2024-04-06T13:35:39.506957Z","shell.execute_reply.started":"2024-04-06T13:35:39.503081Z","shell.execute_reply":"2024-04-06T13:35:39.505936Z"}}},{"cell_type":"markdown","source":"## loading the data where we generated the class-prompts using resnet152","metadata":{}},{"cell_type":"code","source":"# Load the CSV data\ncsv_file_path = '/kaggle/input/text-classification/one152.csv' \ndata = pd.read_csv(csv_file_path)\n\nprint(data.head())","metadata":{"execution":{"iopub.status.busy":"2024-04-06T15:12:44.519443Z","iopub.execute_input":"2024-04-06T15:12:44.519825Z","iopub.status.idle":"2024-04-06T15:12:44.558141Z","shell.execute_reply.started":"2024-04-06T15:12:44.519797Z","shell.execute_reply":"2024-04-06T15:12:44.557154Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"                                                text            img  label  \\\n0           a school bus that was engulfed in flames  img/32674.png      0   \n1  when you ask your dad who is a retired drill s...  img/10246.png      1   \n2    how i see kim burell everytime she grabs a mic!  img/14570.png      1   \n3                           doing o's with the smoke  img/05316.png      0   \n4                im gettin white girl wasted tonight  img/20936.png      0   \n\n           prompt  \n0        volcano   \n1         prison   \n2        gorilla   \n3          cloak   \n4  jigsaw_puzzle   \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## label 1 means harmful content and 0 means normal","metadata":{}},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\nmodel_path = '/kaggle/input/text-classification/resnet152 _ roberta .pth'\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n\n\nmodel.load_state_dict(torch.load(model_path))\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T15:12:47.484677Z","iopub.execute_input":"2024-04-06T15:12:47.485068Z","iopub.status.idle":"2024-04-06T15:12:48.196837Z","shell.execute_reply.started":"2024-04-06T15:12:47.485037Z","shell.execute_reply":"2024-04-06T15:12:48.195798Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"for layer in model.distilbert.embeddings.parameters():\n    layer.requires_grad = False\n\nfor layer in model.distilbert.transformer.layer[:3].parameters():\n    layer.requires_grad = False\n\n# Unfreeze the pre_classifier and classifier layers\nfor layer in model.pre_classifier.parameters():\n    layer.requires_grad = True\n\nfor layer in model.classifier.parameters():\n    layer.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-04-06T15:12:48.198818Z","iopub.execute_input":"2024-04-06T15:12:48.199522Z","iopub.status.idle":"2024-04-06T15:12:48.206326Z","shell.execute_reply.started":"2024-04-06T15:12:48.199482Z","shell.execute_reply":"2024-04-06T15:12:48.205246Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"data['text'] = data['text'] + ' , ' + data['prompt']\ndata.drop(columns=['prompt'], inplace=True)\ndata","metadata":{"execution":{"iopub.status.busy":"2024-04-06T15:12:53.664731Z","iopub.execute_input":"2024-04-06T15:12:53.665082Z","iopub.status.idle":"2024-04-06T15:12:53.685302Z","shell.execute_reply.started":"2024-04-06T15:12:53.665055Z","shell.execute_reply":"2024-04-06T15:12:53.684354Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                                                   text            img  label\n0     a school bus that was engulfed in flames , vol...  img/32674.png      0\n1     when you ask your dad who is a retired drill s...  img/10246.png      1\n2     how i see kim burell everytime she grabs a mic...  img/14570.png      1\n3                     doing o's with the smoke , cloak   img/05316.png      0\n4     im gettin white girl wasted tonight , jigsaw_p...  img/20936.png      0\n...                                                 ...            ...    ...\n9995  when your grandma sees you for the first time ...  img/02631.png      0\n9996  i now declare you sir faggot sucker of cocks ,...  img/95712.png      1\n9997                              help refugees , suit   img/41268.png      0\n9998                jolo jew only live once , sunglass   img/28076.png      0\n9999  there's nothing more ridiculous than when the ...  img/52938.png      0\n\n[10000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>img</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a school bus that was engulfed in flames , vol...</td>\n      <td>img/32674.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>when you ask your dad who is a retired drill s...</td>\n      <td>img/10246.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>how i see kim burell everytime she grabs a mic...</td>\n      <td>img/14570.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>doing o's with the smoke , cloak</td>\n      <td>img/05316.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>im gettin white girl wasted tonight , jigsaw_p...</td>\n      <td>img/20936.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>when your grandma sees you for the first time ...</td>\n      <td>img/02631.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>i now declare you sir faggot sucker of cocks ,...</td>\n      <td>img/95712.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>help refugees , suit</td>\n      <td>img/41268.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>jolo jew only live once , sunglass</td>\n      <td>img/28076.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>there's nothing more ridiculous than when the ...</td>\n      <td>img/52938.png</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"max_length = 90  # Adjust as needed\ntokens = tokenizer.batch_encode_plus(\n    data['text'].tolist(),\n    max_length=max_length,  \n    padding='max_length',\n    truncation=True,\n    return_tensors='pt'\n)\ntokens","metadata":{"execution":{"iopub.status.busy":"2024-04-06T15:12:57.284330Z","iopub.execute_input":"2024-04-06T15:12:57.285268Z","iopub.status.idle":"2024-04-06T15:13:03.853994Z","shell.execute_reply.started":"2024-04-06T15:12:57.285225Z","shell.execute_reply":"2024-04-06T15:13:03.853072Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[ 101, 1037, 2082,  ...,    0,    0,    0],\n        [ 101, 2043, 2017,  ...,    0,    0,    0],\n        [ 101, 2129, 1045,  ...,    0,    0,    0],\n        ...,\n        [ 101, 2393, 8711,  ...,    0,    0,    0],\n        [ 101, 8183, 4135,  ...,    0,    0,    0],\n        [ 101, 2045, 1005,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])}"},"metadata":{}}]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"CUDA is available. Using GPU.\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"CUDA is not available. Using CPU.\")\n    \nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T15:13:03.855727Z","iopub.execute_input":"2024-04-06T15:13:03.856518Z","iopub.status.idle":"2024-04-06T15:13:03.936518Z","shell.execute_reply.started":"2024-04-06T15:13:03.856482Z","shell.execute_reply":"2024-04-06T15:13:03.935431Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"CUDA is available. Using GPU.\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\ninput_ids = torch.tensor(tokens['input_ids'].tolist())\nattention_mask = torch.tensor(tokens['attention_mask'])\nlabels = torch.tensor(data['label'].tolist())\n\ntrain_input_ids, test_input_ids, train_attention_mask, test_attention_mask, train_labels, test_labels = train_test_split(\n    input_ids, attention_mask, labels, test_size=0.2, random_state=42)\n\ntrain_labels = torch.tensor(train_labels.tolist())\ntest_labels = torch.tensor(test_labels.tolist())\n\ntrain_dataset = TensorDataset(train_input_ids, train_attention_mask, train_labels)\ntest_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels)\n\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=500, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=500, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T15:13:08.684220Z","iopub.execute_input":"2024-04-06T15:13:08.685113Z","iopub.status.idle":"2024-04-06T15:13:08.691359Z","shell.execute_reply.started":"2024-04-06T15:13:08.685080Z","shell.execute_reply":"2024-04-06T15:13:08.690312Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"best_validation_loss = float('inf')  # Initialize the best validation loss to infinity\n\nfor epoch in range(2):\n    model.train()\n    total_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    \n    # Training phase\n    for input_ids, attention_mask, labels in train_dataloader:\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        \n        loss = outputs.loss\n        total_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n        predictions = torch.argmax(outputs.logits, dim=1)\n        correct_train += (predictions == labels).sum().item()\n        total_train += labels.size(0)\n        \n    avg_loss = total_loss / len(train_dataloader)\n    accuracy_train = correct_train / total_train\n    \n    # Print training loss and accuracy\n    print(f'Epoch {epoch + 1}, Training Loss: {avg_loss:.4f}, Training Accuracy: {accuracy_train:.4f}', end='')\n    \n    # Validation phase\n    model.eval()\n    total_validation_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    \n    with torch.no_grad():\n        for input_ids, attention_mask, labels in test_dataloader:\n            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            \n            validation_loss = outputs.loss\n            total_validation_loss += validation_loss.item()\n            \n            predictions = torch.argmax(outputs.logits, dim=1)\n            correct_val += (predictions == labels).sum().item()\n            total_val += labels.size(0)\n    \n    avg_validation_loss = total_validation_loss / len(test_dataloader)\n    validation_accuracy = correct_val / total_val\n    \n    # Print validation loss and accuracy\n    print(f', Validation Loss: {avg_validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f}')\n    \n    # Save model if validation loss improves\n    if avg_validation_loss < best_validation_loss:\n        best_validation_loss = avg_validation_loss\n        torch.save(model.state_dict(), f'/kaggle/working/best_classifier.pth')\n \n# Save final model\ntorch.save(model.state_dict(), '/kaggle/working/classifierT.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T15:16:48.139050Z","iopub.execute_input":"2024-04-06T15:16:48.139414Z","iopub.status.idle":"2024-04-06T15:17:34.150083Z","shell.execute_reply.started":"2024-04-06T15:16:48.139385Z","shell.execute_reply":"2024-04-06T15:17:34.148915Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Epoch 1, Training Loss: 0.4354, Training Accuracy: 0.7951, Validation Loss: 0.5545, Validation Accuracy: 0.7325\nEpoch 2, Training Loss: 0.4028, Training Accuracy: 0.8164, Validation Loss: 0.5915, Validation Accuracy: 0.7300\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n  \ntrue_labels = []\npredicted_labels = []\nprobabilities = [] \ncorrect_predictions = 0\ntotal_predictions = 0\n\nwith torch.no_grad():\n    for batch in test_dataloader:\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        \n        _, predicted = torch.max(logits, dim=1)\n        \n        correct_predictions += torch.sum(predicted == labels).item()\n        total_predictions += len(labels)\n        \n        # Store true labels and predicted labels\n        true_labels.extend(labels.tolist())\n        predicted_labels.extend(predicted.tolist())\n        \n        # Store probabilities for AUC calculation\n        probabilities.extend(torch.softmax(logits, dim=1)[:, 1].tolist())\n\n\naccuracy = correct_predictions / total_predictions\nprint(\"Accuracy:\", accuracy)\n\nprecision = precision_score(true_labels, predicted_labels)\nprint(\"Precision:\", precision)\n\nrecall = recall_score(true_labels, predicted_labels)\nprint(\"Recall:\", recall)\n\nf1 = f1_score(true_labels, predicted_labels)\nprint(\"F1 Score:\", f1)\n\nauc = roc_auc_score(true_labels, probabilities)\nprint(\"Area under ROC Curve (AUC):\", auc)\n\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T15:17:52.296206Z","iopub.execute_input":"2024-04-06T15:17:52.296626Z","iopub.status.idle":"2024-04-06T15:17:55.248596Z","shell.execute_reply.started":"2024-04-06T15:17:52.296595Z","shell.execute_reply":"2024-04-06T15:17:55.247505Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Accuracy: 0.73\nPrecision: 0.6895874263261297\nRecall: 0.47885402455661663\nF1 Score: 0.5652173913043478\nArea under ROC Curve (AUC): 0.7780149045289655\nConfusion Matrix:\n[[1109  158]\n [ 382  351]]\n","output_type":"stream"}]}]}